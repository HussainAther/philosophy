# The brain-computer analogy and the computational theory of mind

Brains are only like computers in a specific abstract sense. We can take apart this analogy in the context
of the brain-computer analogy to determine knowledge for philosophy, neuroscience, artificial intelligence,
and other research areas. It's very harmful in many ways to treat the nervous system as the hardware in such 
a way that we need to understand the cognitive science as software when we don't understand the limitations 
of such a metaphor. Any theory of anatomical connection we demonstrate in vertebrate nervous systems may give
us a basic description of what happens at each stage, but don't tell us how a given input relates to a certain
output. Instead, they obfuscate the description of the brain by using unneccessary comparisons to explain
phenomena that are better off explained by describing the phenomena directly and precisely.

An output of a computer depends on its program, input, and functional stages that lead to the output.

## Intentionality 

If we treat propositional attitudes with intentionality as a physical properties, we can build a computer
with states that have genuine intentionality. But no computer model that stimulates human propositional
attitudes will have genuine intentional states. Intentionality of propositional attitudes isn't a physical
property. 

We may consider the network theory of meaning (or holistic theory or conceptual-role theory) such that the meaning
of an expression plays a role in its internal representatinoal economy. This way it relates to sensory input and
behavioral output. Meaning is relational as an expression's meaning is a function of its inferential and computational
role in a person's internal system. A robot that behaves like a human is still subject to the quesitno of whether
those thoughts it generates have the same meaning that represent our own meaning. Assigning meaning to the internal
states of a robot would be applying a double standard arbitrarily with no useful purpose. The robot's internal 
machinery doesn't change that it believes, wants, and understands things. The robot's intentional states depend
on how complex its internal informational network of states it has.

We need altogether a better theory of representation in organisms much the same way we have theoretical definitions
and ideas of what molecules, proteins, and neutrons are. 

## Levels of organization

The brain-computer analogy presents a problem of complexity that we know we have in the brain as that relates to
organization of a computer. The semantic, syntactic, and mechanistic levels introduce issues with the level of the
algorithm and the structural implementation of those features. Neurobiological theory challenges the way of
specifiying the organizational description. The levels of membrane, cell, synapse, cell assembly, circuit, and behavior
can be argued as levels, but even within them we have different partitions of the levels of themselves. We can also determine
levels by the research methods such as how through learning and memory we can take a cellular approach to show 
modifications in presynaptic neurotransmitter releases in habituation. Which level is functional and which level is structural
is difficult to determine, too. 

## Causality

A calculator's representation and rules for manipulating representations can explain its behavior much the same way
we describe how and why people do what they do. Philosopher Zenon Pylyshyn said we explain why a machine does
something with certain interpretations of the symbols in a domain. Psychologcial theory would cross-classify
categories of neurophysiology theory that would make neurophysiological generalizations miss important relations
that are only describably at the level at which representations are referred to. The psychological maps only would 
map onto an indefinite mix of neurobiological categories.

## Connectionism (Parallel distributed processing)

As philosopher Paul Churchland has argued, we may use connectionism or parallel distributed processing (PDP) in figuring out the computational
operatinos in nervous systems in such a way we may use computer models of parallel distributed systems to generate the appropriate
phenomena on a higher level (cognitive science, psychology, etc.) from basic processes (neuroscience, physics, etc.).

### Tensor network theory

Neuroscientists began the theory began on the cerebellum because it has a limited nubmer of neuron types that are each
distinct on a physiological level and connected in a specific way that the cerebellar cortex produces the Purkinje cell
with two different cell systems as input. Using wiring diagrams of cerebellar neurons to describe the connections accept
input and result output in a parallel manner. We have a trade-off between detail to understand the system with how the array
itself processes information. Through tensor network theory we attempt to use principles from mathematics, physics, and computer
science in understanding how these systems may model the nervous system. We can create a schematic neuron to find out more about
the patterns of neurons arranged in mathematical arrays. Though the model may be limited by the assumptions of casual theory
and epistemic concerns of the phenoemna we attempt to describe, it's a nice heuristic to see something we wouldn't otherwise
see through single-cell data. We may use concepts from linear algebra and statistics to create output vectors in a coordinate
system such that the corresponding tensor matrix governs the transformtaion of ensembles from input-output relationships
by the corresponding reference frame. The spiking frequency defines a point on an axis of the coordinate system with the output
a vector in the space of the output neurons. We may generalize a tensor mathematical to transform vectors into other vectors
such that we address the basic problem of functionalist sensorimotor control as going from one different coordinate system
to another. 

When we figure out what the mind-brain does, then how it might implement various functions in a top-down manner among different
levels of science, the theorizing is highyl constrained, yet very well-informed, by the data of the level at which we implement.
But, with tensor network theory, we wouldn't label these processes as top-down, but, rather, from lower-level fundamental processes
to higher-level descriptions. 

We use a tensor transformer to transform in a way we still need: to transform vectors in sensory space to vectors in motor space. 
We may deform one phase space to get an object in the other one using represesntations as positions in phase space and computations
as coordinate transformations between phase spaces. The Pellionisz-Llinás approach uses sensorimotor problems constrained by
realistic creatures as a method of reducing at bottom the problem of making coordinate transformations between phase spaces. In tensor
network theory, we look for functional relationships between connected cell assemblies and investigate them for properties relevant
to phase spaces much the same way a computer or artifically intelligent machine searches for solutions among sentence-related
criteria. Such AI would require this knowledge to determine what to do.

Tensor network theory still needs to unify results across the disciplines of cogntive science, psychology, and neuroscience in such
a way that we can construct a universalized, common set of rules with coherent explanations that we can experimentally test and verify.
Attempts to describe the vestibulu-ocular reflex, the method of determining movement from visual image stimuli, using semicircular canals
of the vestibular system, we furhter imagine each eyeball detecting the images and communicating to those receptors. This system needs
to determine how muscles contract so the eyes move in a way to refelect the head movements. The corresponding tensor approach would imagine
the system converting a head position vector into a vector that describse muscle positions. The transformation 
from vestibular to oculomotor, according to the Pellionisz-Llinás hypothesis, takes a premotor vector intoa motor vector. The vestibulur 
organ, we can show, has a set of positions it prefers that we can call an eigenposition. 

We further pose Churchland's phase-space sandwhich hypothesis that describes spatial organizatino of maps layer so that the corresponding
neurons may perform any transformation from two dimensions to two dimensions. The maps representing phase spaces aren't literally stacked upon one another. 
They may remain spatially distant from each other. With the topology of the cortical area, we still have to answer whether tensor network
theory can account for neuroplasticity. Covariant proprioception vectors can give feedback about motor performance which can further
provide information of trasnformations of the cerebellar matrix. The matrix would then turn into a state such that its eigenvectors
are identical so that they are the "correct" coordinate transformation. Climbing fibers of the cerebellum may provide a pathway
for reverbative feedback that modifies transformational properties of the cerebellar network. This is found in AI that use relaxation
algorithms.  

## Mental states

If we determine how behavior related to cognition and complexity emerge from the basic neurophysiological theories that govern
sensorimotor control, we can determine the nature and dynamics of cognition. We may construct representations at abstract levels of 
organization that correspond to cognitive activity as the way sentiential representations act according to logical rules. Phase spaces
may recognize certain features as humans do, such as eyes of faces or shapes of animals. We may describe phase spaces in such a way
that they're occupied by these sensory stimuli. Using the cones of photoreceptors' reflectances responsible for color, we can demonstrate
a computational problem of how to represent a unique color with a triplet of reflectance values. 

## Parallel models 

Sequential models can be powerful, AI researchers have shown their ineffectiveness in simulation of fundamental cognitive processes
in areas of pattern recognition and knowledge storage and retrieval. The differnces between human brains and computer science phenomena
only furthers these issues. Humans and computers use very different methods of storing memory as well as methods of connectivity among
humans neurons against artificial ones. 

The Hinton-Sejnowski visual recognition system uses a network of two sets of binary units: one for detecting input from external stimuli and
the other for connecting detectors to nondetecting units. These networks determine the truth and validity of hypotheses by gauging
which units fire and which don't. It performs a cooperative search in which these assemblies vote for various outcomes and the one
with the most votes wins. The relationships between various hypotheses depend upon synaptic weights using probabilitiy functions
and distributions. They also perform relaxations that cool the system such that it may take different molecular organizations in an annealing process.
During this process the crystalline structures have a global energy minimum that parallels adding noise to the system.  
From these fluctuations in noise, the system breaks out of superficial minimima. The Metropolis-Hastings algorithm lets us 
gauge locally improbably hypotheses such that they may win over other hypotheses. 

To make the model reflect empirical data in neuroscience, we must show it accounts for processing of various neurobiologiacl pathways.
Computer vision models need to account for contours of perception as well as emergent phenomena such as recognizing how a property
of an image emerges from various strucutres working in a dynamic, systemic manner of the visual image itself. Connectionists could
update their brain-computer models using evolution the same way sensorimotor mechanisms have to suit a simultaneous solution
in visual recognition.

## A computational theory of mind

We distinguish between different levels of description of computational proceseses. These levels have certain reducible 
relationships among them in which we can make varying levels of commitment to the reductionism between them. The theory of symbolic computational
functionalism of the computational theory of mind (known as computationalism) lets minds manipulate discrete, defined symbols
to model discrete, defined logical structures and computer languages. A human mind may be a deterministic finite state automata under
this theory, and the theory is independent of implementation. Even if different beings have different physical structures of themselves,
they may have similar or the same mental states. Philosopher Patricia Churchland and neuroscientist Terrence Sejnowski have criticized
that the implementation is important, especially as lower theroetical levels (such as neuroscientific phenomena) are significant
to higher ones. Opponents may aslo argue that the representations of computationalism don't tell us anything more than
the non-representational descriptions do. Using representation may just amount to an unnecessary model or analogy that only steers us
away from the precise, defined meaning of the world. 

The computationalist may respond she doesn't want to make a physiologically accurate human mind model, but wants to find intelligent
features for any agent. In AI, one might want to solve a problem in computational space that doesn't represent human features. 
She may also respond that representational theories note when the features of representation, such as the similarity between representations
and their objects and how accruate they are, in such a way that the representational theory is more effective, valid, and justified
than non-representational theories. 

We may account for the intentional nature of basic emotions even if they have a physiological component to them, such as changes in facial expression or bodily mechanisms. Weak content cognitivism, the belief taht emotions are or are caused by propositional attitudes, may 
attack this relationship of emotions to a bodily response, but the relationship of emotions to beliefs doesn't mean all emotions are caused
by propositional attidues like beliefs. A computational theory of mind should account for emotoinal effects and similar affects that
influence perception and judgement. But the changes in emotions don't seem discrete as though there were differences in logical systems
as we described with the Hinton-Sejnowski theory or with tensor network theory. Emotions form a continous gradient that doesn't seem to
arise from a sort of combinatorial engine that the computationalist theory would argue. We would need a semantic activation model that adheres to principles of symbolic computational functionalism as well.  

The connectionist model describes effects of some emotions, but doesn't model emotion itself. To allow semantic activation models to use emotions
in a cognitive position would mean that emotions, in some sense, are the same as similar cognitive categories such as "visual stimuli" or "beliefs." 
The other features of emotion, though, semantic activation models need to describe implementation-dependent details of the model itself. 

The computationalist position also has issues with how to model affects, such as those of basic emotions, independently of cognition yet still
play a role in rational human behavior. The computationalist may be inclined to treat emotions as external or even unnecessary to their models.
Computationalists also can't account for the effects of basic emotions on perception and categorization using their current models.
These emotions themselves may be more fundamental to those perceptions and categories that we form, given their unique nature on intellectual
perception. 

## Neural circuitry

We may imagine the brain as a computer through neural circuitry excitation/inhibitation ratios as a property for cognitive
function in cortical circuits. Research in circuit function on synaptic parameters in memory and decision-making
can give us parameter spcaes to reduce NMDAR conductance strengths from excitatory pyramidal neurons to inhibitory
interneurons or excitatory pyramidal neurons. We may apply dopamine neuronal activity using a bifurcation diagram.
In math, we generally use bifurcation plots to study dynamical system behavior with respect to parameter variations
or similar perturbations. We may use Ohm's law to relate current, potential, capacitance, and resistance among 
membrane channel dynamics. The dopamine neuron uses ionic currents using the Hodgkin-Huxley models. We can use
these fundamentals to create circuit models of neuronal activity using population firing rates to calculate
dopamine efflux in the nucleus accumbens.

## Functional connectivity

Functional connectivity (FC) is the statistical correlation of neural activity to two different regions. We find
evidence for this at the micro-circuit level (the relationship between structure and function through anatomical 
and neurophysiological research techniques). We can integrate information across brain networks using large-scale
brain connectivity at finer temporal and spatial resolution. If we introduce spatiotemporal models of resting-state
networks, we can analyze the time frequency of these networks using wavelet anaylsis, sliding-windows, and similar
methods of describing temporal correlations between the networks. 

## Structural connectivity 

Structural connectivity (SC) are the long-range anatomical connections among brain areas through white-matter
fiber projections. We use fiber tracking using bounded diffusion of molecules in water to create non-invasive
connectivity maps. In the past scientists used diffusion tensor imaging (DTI), we track neural fibers, but more 
recent studies have used advances in graph theory for much more research on topological features in brain connectivity. 

We can characterize the relationship between FC and SC as the former relying on connections between areas and the
latter the physical characteristics of the fibers. Effective connectivity (EC) characterizes the interactions between
visual processing regions (a psychophysiological interaction analysis) using structural equation modeling (SEM) 
based on minimization of predicted and observed depdent variables. EC also refers to the broader definition of SC
that captures the features that shape connectivity like synaptic strengths, neurotransmitter concentrations, and
neural excitability. Through both model-driven and data-driven approaches (the former generation signals under 
assumptions and the latter using statistics, information theoreitcal measures, or phase relationships to extract
EC), we can infer EC and the topology of these networks. Using     
