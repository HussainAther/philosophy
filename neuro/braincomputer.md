# The brain-computer analogy

Brains are only like computers in a specific abstract sense. We can take apart this analogy in the context
of the brain-computer analogy to determine knowledge for philosophy, neuroscience, artificial intelligence,
and other research areas. It's very harmful in many ways to treat the nervous system as the hardware in such 
a way that we need to understand the cognitive science as software when we don't understand the limitations 
of such a metaphor. Any theory of anatomical connection we demonstrate in vertebrate nervous systems may give
us a basic description of what happens at each stage, but don't tell us how a given input relates to a certain
output. Instead, they obfuscate the description of the brain by using unneccessary comparisons to explain
phenomena that are better off explained by describing the phenomena directly and precisely.

An output of a computer depends on its program, input, and functional stages that lead to the output.

## Intentionality 

If we treat propositional attitudes with intentionality as a physical properties, we can build a computer
with states that have genuine intentionality. But no computer model that stimulates human propositional
attitudes will have genuine intentional states. Intentionality of propositional attitudes isn't a physical
property. 

We may consider the network theory of meaning (or holistic theory or conceptual-role theory) such that the meaning
of an expression plays a role in its internal representatinoal economy. This way it relates to sensory input and
behavioral output. Meaning is relational as an expression's meaning is a function of its inferential and computational
role in a person's internal system. A robot that behaves like a human is still subject to the quesitno of whether
those thoughts it generates have the same meaning that represent our own meaning. Assigning meaning to the internal
states of a robot would be applying a double standard arbitrarily with no useful purpose. The robot's internal 
machinery doesn't change that it believes, wants, and understands things. The robot's intentional states depend
on how complex its internal informational network of states it has.

We need altogether a better theory of representation in organisms much the same way we have theoretical definitions
and ideas of what molecules, proteins, and neutrons are. 

## Levels of organization

The brain-computer analogy presents a problem of complexity that we know we have in the brain as that relates to
organization of a computer. The semantic, syntactic, and mechanistic levels introduce issues with the level of the
algorithm and the structural implementation of those features. Neurobiological theory challenges the way of
specifiying the organizational description. The levels of membrane, cell, synapse, cell assembly, circuit, and behavior
can be argued as levels, but even within them we have different partitions of the levels of themselves. We can also determine
levels by the research methods such as how through learning and memory we can take a cellular approach to show 
modifications in presynaptic neurotransmitter releases in habituation. Which level is functional and which level is structural
is difficult to determine, too. 

## Causality

A calculator's representation and rules for manipulating representations can explain its behavior much the same way
we describe how and why people do what they do. Philosopher Zenon Pylyshyn said we explain why a machine does
something with certain interpretations of the symbols in a domain. Psychologcial theory would cross-classify
categories of neurophysiology theory that would make neurophysiological generalizations miss important relations
that are only describably at the level at which representations are referred to. The psychological maps only would 
map onto an indefinite mix of neurobiological categories.

## Connectionism (Parallel distributed processing)

As philosopher Paul Churchland has argued, we may use connectionism or parallel distributed processing (PDP) in figuring out the computational
operatinos in nervous systems in such a way we may use computer models of parallel distributed systems to generate the appropriate
phenomena on a higher level (cognitive science, psychology, etc.) from basic processes (neuroscience, physics, etc.).

### Tensor network theory

Neuroscientists began the theory began on the cerebellum because it has a limited nubmer of neuron types that are each
distinct on a physiological level and connected in a specific way that the cerebellar cortex produces the Purkinje cell
with two different cell systems as input. Using wiring diagrams of cerebellar neurons to describe the connections accept
input and result output in a parallel manner. We have a trade-off between detail to understand the system with how the array
itself processes information. Through tensor network theory we attempt to use principles from mathematics, physics, and computer
science in understanding how these systems may model the nervous system. We can create a schematic neuron to find out more about
the patterns of neurons arranged in mathematical arrays. Though the model may be limited by the assumptions of casual theory
and epistemic concerns of the phenoemna we attempt to describe, it's a nice heuristic to see something we wouldn't otherwise
see through single-cell data. We may use concepts from linear algebra and statistics to create output vectors in a coordinate
system such that the corresponding tensor matrix governs the transformtaion of ensembles from input-output relationships
by the corresponding reference frame. The spiking frequency defines a point on an axis of the coordinate system with the output
a vector in the space of the output neurons. We may generalize a tensor mathematical to transform vectors into other vectors
such that we address the basic problem of functionalist sensorimotor control as going from one different coordinate system
to another. 

When we figure out what the mind-brain does, then how it might implement various functions in a top-down manner among different
levels of science, the theorizing is highyl constrained, yet very well-informed, by the data of the level at which we implement.
But, with tensor network theory, we wouldn't label these processes as top-down, but, rather, from lower-level fundamental processes
to higher-level descriptions. 

We use a tensor transformer to transform in a way we still need: to transform vectors in sensory space to vectors in motor space. 
We may deform one phase space to get an object in the other one using represesntations as positions in phase space and computations
as coordinate transformations between phase spaces. The Pellionisz-Llin√°s approach uses sensorimotor problems constrained by
realistic creatures as a method of reducing at bottom the problem of making coordinate transformations between phase spaces.  
