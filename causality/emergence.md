# Contextual emergence

Contextual emergence characterizes a specific kind of relationship between different 
domains of scientific descriptions of particular phenomena. Although these domains 
are not ordered strictly hierarchically, one often speaks of lower and higher levels 
of description, where lower levels are considered as more fundamental in a certain 
sense. As a rule, phenomena at higher levels of description are more complex than 
phenomena at lower levels. This increasing complexity depends on contingent conditions, 
so-called contexts, that must be taken into account for an appropriate description.

The basic idea of contextual emergence is to establish a well-defined interlevel relation 
between a lower level L and a higher level H of a system. This is done by a two-step 
procedure that leads in a systematic and formal way (1) from an individual description 
Li to a statistical description Ls and (2) from Ls to an individual description Hi. 
This scheme can in principle be iterated across any connected set of descriptions, so 
that it is applicable to any case that can be formulated precisely enough to be a 
sensible subject of a scientific investigation.

The essential goal of step (1) is the identification of equivalence classes of individual 
states that are indistinguishable with respect to a particular ensemble property. This step 
implements the multiple realizability of statistical states in Ls (which will be the basis 
for individual states in Hi) by individual states in Li. The equivalence classes at L can 
be regarded as cells of a partition. Each cell is the support of a (probability) distribution 
representing a statistical state, encoding limited knowledge about individual states

The essential goal of step (2) is the assignment of individual states at level H to coextensional 
statistical states at level L. This is impossible without additional information about the 
desired level-H description. In other words, it requires the choice of a context setting the 
framework for the set of observables (properties) at level H that is to be constructed from 
level L. The chosen context provides conditions that can be implemented as stability criteria at 
level L. It is crucial that such stability conditions cannot be specified without knowledge 
about the context at level H. In this sense the context yields a top-down constraint, or 
downward confinement (sometimes misleadingly called downward causation).

The notion of stability induced by context is of paramount significance for contextual emergence. 
Roughly speaking, stability refers to the fact that some system is robust under (small) 
perturbations - for instance, if (small) perturbations of a homeostatic or equilibrium 
state are damped out by the dynamics, so that the initial state is (asymptotically) retained. 
The more complicated notion of a stable partition of a state space is based on the idea of 
coarse-grained states, i.e. cells of a partition whose boundaries are (approximately) maintained under the dynamics.

Stability criteria guarantee that the statistical states of Ls are based on a robust partition 
so that the emergent observables in Hi are well-defined. (For instance, if a partition is not 
stable under the dynamics of the system at Li, the assignment of states in Hi will change over 
time and, thus, will be ill-defined.) Implementing a contingent context of Hi as a stability 
criterion in Li yields a proper partitioning for Ls. In this way, the lower-level state 
space is endowed with a new, contextual topology.

From a slightly different perspective, the context selected at level H decides which details 
in Li are relevant and which are irrelevant for individual states in Hi. Differences among all 
those individual states at Li that fall into the same equivalence class at Ls are irrelevant 
for the chosen context. In this sense, the stability condition determining the contextual 
partition at Ls is also a relevance condition.

The interplay of context and stability across levels of description is the core of contextual 
emergence. Its proper implementation requires an appropriate definition of individual and statistical 
states at these levels. This means in particular that it would not be possible to construct 
emergent observables in Hi from Li directly, without the intermediate step to Ls. And it would 
be equally impossible to construct these emergent observables without the downward confinement 
arising from higher-level contextual constraints.

In this spirit, bottom-up and top-down strategies are interlocked with one another in such a way 
that the construction of contextually emergent observables is self-consistent. Higher-level 
contexts are required to implement lower-level stability conditions leading to proper lower-level 
partitions, which in turn are needed to define those lower-level statistical states that are 
co-extensional (not necessarily identical) with higher-level individual states and their associated observables.

As an example, consider the transition from classical point mechanics over statistical mechanics to 
thermodynamics (Bishop and Atmanspacher 2006). Step (1) in the discussion above is here the step from 
point mechanics to statistical mechanics, essentially based on the formation of an ensemble distribution. 
Particular properties of a many-particle system are defined in terms of a statistical ensemble description 
(e.g., as moments of a many-particle distribution function) which refers to the statistical state of 
an ensemble (Ls) rather than the individual states of single particles (Li).

An example for an observable associated with the statistical state of a many-particle system is its 
mean kinetic energy, which can be calculated from the the Maxwell-Boltzmann distribution of the momenta 
of all N particles. The expectation value of kinetic energy is defined as the limit of its mean value 
for infinite N.

Step (2) is the step from statistical mechanics to thermodynamics. Concerning observables, this is the 
step from the expectation value of a momentum distribution of a particle ensemble (Ls) to the temperature 
of the system as a whole (Hi). In many standard philosophical discussions this step is mischaracterized 
by the false claim that the thermodynamic temperature of a gas is identical with the mean kinetic energy 
of the molecules which constitute the gas. A proper discussion of the details was not available for a 
long time and has been achieved by Haag et al. (1974) and Takesaki (1970) in the framework of quantum 
field theory.

The main conceptual point in step (2) is that thermodynamic observables such as temperature presume 
thermodynamic equilibrium as a crucial assumption serving as a contextual condition. It is formulated 
in the zeroth law of thermodynamics and not available at the level of statistical mechanics. The very 
concept of temperature is thus foreign to statistical mechanics and pertains to the level of thermodynamics 
alone. (Needless to say, there are more thermodynamic observables in addition to temperature. Note that 
also a feature so fundamental as irreversibility in thermodynamics depends crucially on the context of 
thermal equilibrium.)

The context of thermal equilibrium (Hi) can be recast in terms of a class of distinguished statistical 
states (Ls), the so-called Kubo-Martin-Schwinger (KMS) states. These states are defined by the KMS 
condition which characterizes the (structural) stability of a KMS state against local perturbations. 
(More precisely, this includes stationarity, ergodicity, and mixing). Hence, the KMS condition 
implements the zeroth law of thermodynamics as a stability criterion at the level of statistical 
mechanics. (The second law of thermodynamics expresses this stability in terms of a maximization 
of entropy for thermal equilibrium states. Equivalently, the free energy of the system is minimal 
in thermal equilibrium.)

Statistical KMS states induce a contextual topology in the state space of statistical mechanics (Ls) 
which is basically a coarse-grained version of the topology of Li. This means nothing else than a 
partitioning of the state space into cells, leading to statistical states (Ls) that represent equivalence 
classes of individual states (Li). They form ensembles of states that are indistinguishable with 
respect to their mean kinetic energy and can be assigned the same temperature (Hi). Differences 
between individual states at Li falling into the same equivalence class at Ls are irrelevant with 
respect to a particular temperature at Hi.

While step (1) formulates statistical states from individual states at the mechanical level of 
description, step (2) provides individual thermal states from statistical mechanical states. 
Along with this step goes a definition of new, emergent thermal observables that are coextensive, 
but not identical with mechanical observables. All this is guided by and impossible without 
the explicit use of the context of thermal equilibrium.

The example of the relation between mechanics and thermodynamics is particularly valuable for 
the discussion of contextual emergence because it illustrates the two essential construction 
steps in great detail. There are other examples in physics and chemistry which can be discussed 
in terms of contextual emergence: emergence of geometric optics from electrodynamics, emergence 
of electrical engineering concepts from electrodynamics, emergence of chirality 
as a classical observable from quantum mechanics, emergence of diffusion and friction of a 
quantum particle in a thermal medium, emergence of hydrodynamic properties from many-particle theory. 

If descriptions at L and H are well established, as it is the case in the preceding example, 
formally precise interlevel relations can be set up fairly straightforwardly. The situation 
becomes more challenging, though, when no such established descriptions are available, e.g. 
in cognitive neuroscience or consciousness studies, where relations between neural and mental 
descriptions are considered. Even there, contextual emergence has been proven viable for the 
construction of emergent mental states (e.g., the identification of neural correlates of 
conscious states). That brain activity provides necessary but not sufficient conditions for 
mental states, which is a key feature of contextual emergence, becomes increasingly clear 
even among practicing neuroscientists.

A basic element of theoretical and computational neuroscience are the Hodgkin-Huxley equations 
for the generation and propagation of action potentials. The Hodgkin-Huxley equations form a 
system of four ordinary nonlinear differential equations: one electric conductance equation 
for transmembrane currents, and three master equations describing the opening kinetics of 
sodium and potassium ion channels. At a higher-level description of ion channel functioning, 
these equations characterize a deterministic dynamical system. However, at a lower-level 
description, the presence of master equations within the Hodgkin-Huxley system indicates a 
stochastic approach in terms of transition probabilities of Markov processes.

A closer inspection of the Hodgkin-Huxley equations reveals that the dynamics of neuronal action 
potentials is actually contextually emergent over (at least) three levels of description. 
At the first and lowest level, ion channels must be treated as macro-molecular quantum objects 
that are governed by a many-particle Schrödinger equation. This Schrödinger equation describes 
a highly entangled state of electrons and atomic nuclei as a whole, which does not allow 
an interpretation in terms of molecular structures such as an ion channel with a pore that is 
either closed or open. The molecular structure of an ion channel is contextually emergent 
through the Born-Oppenheimer approximation separating electronic and nucleonic wave functions. 
After that separation, the electronic quantum dynamics becomes constrained to a (relatively) 
rigid nucleonic frame that now possesses a classical spatial structure.

At a second level, the fluctuations of the spatial structure of an ion channel must be treated 
as a stochastic process. Under the respective stability conditions for such processes (stationarity, 
ergodicity, mixing a continuous master equation for the molecular configurations can be derived.  
Finally, at the third level, a contextual coarse-graining of configuration space into four closed 
and one open state (here for the potassium channel), yields the master equations of the Hodgkin-Huxley 
system as a contextually emergent description.

Contextual emergence addresses both the construction of a partition at a lower-level description and 
the application of a higher-level context to do this in a way adapted to a specific higher-level 
description. Two alternative strategies have been proposed to contruct Hi-states ("neural macrostates") 
from Li-states ("neural microstates") previously: one by Amari and collaborators and another one by 
Crutchfield and collaborators.

For the contextual emergence of mental states from neural states, the first desideratum is the 
specification of proper levels L and H . With respect to L , one needs to specify whether states 
of neurons, of neural assemblies or of the brain as a whole are to be considered; and with respect 
to H a class of mental states reflecting the situation under study needs to be defined. In a purely 
theoretical approach, this can be tedious, but in empirical investigations the experimental setup 
can often be used for this purpose. For instance, experimental protocols include a task for subjects 
that defines possible mental states, and they include procedures to record brain states.

The first step is to find a proper assignment of Li and Ls at the neural level. A good candidate 
for Li are the properties of individual neurons. Then the first task is to construct Ls in such 
a way that statistical states are based on equivalence classes of those individual states whose 
differences are irrelevant with respect to a given mental state at level H. This reflects that 
a neural correlate of a conscious mental state can be multiply realized by "minimally sufficient 
neural subsystems correlated with states of consciousness" from David Chalmers "What is a neural 
correlate of consciousness?".

In order to identify such a subsystem, we need to select a context at the level of mental states. 
As one among many possibilities, one may use the concept of "phenomenal families" for this purpose. 
A phenomenal family is a set of mutually exclusive phenomenal (mental) states that jointly partition 
the space of mental states. Starting with something like creature consciousness, that is being conscious 
versus being not conscious, one can define increasingly refined levels of phenomenal states of background 
consciousness (awake, dreaming, sleep, anesthesia, ...), wake consciousness (perceptual, cognitive, 
affective, ...), perceptual consciousness (visual, auditory, tactile, ...), visual consciousness 
(color, form, location, ...), and so on.

Selecting one of these levels provides a context which can then be implemented as a stability criterion 
at Ls. In cases like the neural system, where complicated dynamics far from thermal equilibrium are 
involved, a powerful method to do so uses the neurodynamics itself to find proper statistical states. 
The essential point is to identify a partition of the neural state space whose cells are robust under 
the dynamics. This guarantees that individual mental states Hi, defined on the basis of statistical 
neural states Ls, remain well-defined as the system develops in time. The reason is that differences 
between individual neural states Li belonging to the same statistical state Ls remain irrelevant as the 
system develops in time.

The construction of statistical neural states is strikingly analogous to what leads Butterfield to the 
notion of meshing dynamics. In his terminology, L-dynamics and H-dynamics mesh if coarse graining and 
time evolution commute. From the perspective of contextual emergence, meshing is guaranteed by the 
stability criterion induced by the higher-level context. In this picture, meshing translates into 
the topological equivalence of the two dynamics.

For multiple fixed points, their basins of attraction represent proper cells, while chaotic attractors 
need to be coarse-grained by so-called generating partitions. From experimental data, both can be numerically 
determined by partitions leading to Markov chains. These partitions yield a rigorous theoretical constraint 
for the proper definition of stable mental states. The formal tools for the mathematical procedure derive 
from the fields of ergodic theory and symbolic dynamics.

A pertinent example for the application of contextual emergence to experimental data is the relation 
between mental states and EEG dynamics. In a recent study, Allefeld tested the method using data 
from the EEG of subjects with sporadic epileptic seizures. This means that the neural level is 
characterized by brain states recorded via EEG, while the context of normal and epileptic mental 
states essentially requires a bipartition of that neural state space.

The data analytic procedure rests on ideas by Gaveau and Schulman, Froyland, and Deuflhard and Weber. 
It starts with a (for instance) 20-channel EEG recording, giving rise to a state space of dimension 20, 
which can be reduced to a lower number by restricting to principal components (PC). On the resulting 
low-dimensional state space, a homogeneous grid of cells is imposed in order to set up a Markov 
transition matrix T reflecting the EEG dynamics on a fine-grained auxiliary partition. 

The eigenvalues of T express relaxation time scales for the dynamics which can be ordered by size. 
Gaps between successive relaxation times indicate groupings referring to mental states defined by 
partitions of neural states of increasing refinement. The first group is often sufficient for the 
distinction of "target" mental states.

The eigenvectors corresponding to the eigenvalues of T span an eigenvector space, in which the 
measured PC-compactified states form a simplex. For instance, three leading eigenvalues allow a 
representation of neural states in a two-dimensional eigenvector space which yields a 2-simpex 
with 3 vertices (a triangle). Classifying the measured neural states according to their distance 
from the vertices of the simplex then leads to three clusters of neural data. They can be coded 
and identified in the PC-state space, where the clusters appear as non-intersecting convex sets 
distinguishing one normal state and one seizure state (composed of two substates).

Finally, the result of the partitioning can be inspected in the originally recorded time series to 
check whether mental states are reliably assigned to the correct episodes in the EEG dynamics. 
The study by Allefeld shows perfect agreement between the distinction of normal and epileptic 
states and the bipartition resulting from the spectral analysis of the neural transition matrix.

Another EEG-segmentation algorithm that uses the recurrence structure of multivariate time series 
has been suggested by beim Graben and Hutt. Their recurrence structure analysis (RSA) partitions 
the state space into clusters of recurrent, and therefore, overlapping balls obtained from the 
recurrence plot of the dynamical system. Different choices of the radius r of the balls leads to 
potentially different segmentations of the time series from the corresponding partitions. An 
optimal choice of r, however, will ideally reflect the dwell times within metastable states and 
the transitions between metastable states. This can be described by a Markov chain with one 
distinguished transient state and other states representing the metastable states in the dynamics.

The deviation of a given contextual segmentation from the optimal segmentation can be assessed 
using a utility function whose maximization leads to a contextually emergent brain microstate 
segmentation of the EEG. Applying this technique to EEG data from anesthetized ferrets and to 
event-related brain potentials from human language-processing experiments revealed good correlation 
with mental states.

According to Dennett, the intentional stance can be applied to the prediction of any system's 
behavior that is too complex to be treated as either a physical or a designed system. Intentional 
systems in this sense are systems whose behavior is predictable upon ascribing beliefs and desires to 
their internal states. Examples for intentional systems range from thermostats and chess computers 
over "magnetic snakes" to "true believers", e.g. human beings.

To make meaningful predictions of a system, several necessary and sufficient conditions on the 
system's dynamics must be fulfilled (beim Graben 2014). First of all, the system's dynamics 
must be non-trivial, thus excluding most kinds of linear systems with periodic oscillations 
or damped relaxations. The class of putative intentional systems can be embedded into an 
"intentional hierarchy" ranging from the general case of nonlinear nonequilibrium dissipative 
systems to more specific intentional systems and "true believers" as a subclass.

Being a physical system is necessary for being a nonlinear dissipative nonequilibrium system; 
being a nonlinear dissipative nonequilibrium system is necessary for being an intentional system; 
and being an intentional system is necessary for being a true believer. Moreover, sufficient 
conditions within the intentional hierarchy implement contextual stability conditions.

The most general case corresponds to the transition from equilibrium thermodynamics to fluid dynamics: 
The phenomenal laws of fluid dynamics (the Navier-Stokes equations) emerge from statistical mechanics 
under the assumption of "local equilibrium". At the next level, several sufficient boundary conditions 
must be selected to give rise to processes of self-organization, nicely illustrated by means of "magnetic 
snakes". Then, a rationality constraint is imposed for optimal dissipation of pumped energy. 
Finally, "true believers" are contextually emergent as intentional systems that are stable under 
mutual adoption of the intentional stance. 

Another application of contextual emergence refers to the symbol grounding problem posed by Harnad. The 
key issue of symbol grounding is the problem of assigning meaning to symbols on purely syntactic grounds, 
as proposed by cognitivists such as Fodor and Pylyshin (1988). This entails the question of how conscious 
mental states can be characterized by their neural correlates, see Atmanspacher and beim Graben. Viewed 
from a more general perspective, symbol grounding has to do with the relation between analog and digital 
systems, the way in which syntactic digital symbols are related to the analog behavior of a system they 
describe symbolically.

An instructive example for this distinction is given by dynamical automata. These are piecewise linear 
(globally nonlinear) time-discrete maps over a two-dimensional state space which assume their interpretation 
as symbolic computers through a rectangular partition of the unit square. Interestingly, a single point 
trajectory, i.e. the evolution of microstates (at a lower level description) is not fully interpretable as 
symbolic computation. Therefore, one has to consider (higher-level) macrostates, based on ensembles of 
state space points (or probability distributions of points) that evolve under the dynamics.

Beim Graben and Potthast showed that only uniform probability distributions with rectangular support 
exhibit a stable dynamics that is interpretable as computation. Thus, the huge space of possible 
probability distributions must be contextually restricted to the subclass of uniform probability 
distributions in order to obtain meaningfully grounded symbolic processes. In this sense, symbol 
grounding is contextually emergent.

It is a long-standing philosophical puzzle how the mind can be causally relevant in a physical world: 
the problem of mental causation the question of how mental phenomena can be causes is of high significance 
for an adequate comprehension of scientific disciplines such as psychology and cognitive neuroscience. 
Moreover, mental causation is crucial for our everyday understanding of what it means to be an agent 
in a natural and social environment. Without the causal efficacy of mental states the notion of agency 
would be nonsensical.

One of the reasons why the causal efficacy of the mental has appeared questionable is that a 
horizontal (intralevel, diachronic) determination of a mental state by prior mental states 
seems to be inconsistent with a vertical (interlevel, synchronic) determination of that mental 
state by neural states. In a series of influential papers and books, Kim has presented his much 
discussed supervenience argument (also known as exclusion argument), which ultimately amounts to 
the dilemma that mental states either are causally inefficacious or they hold the threat of 
overdetermining neural states. In other words: either mental events play no horizontally 
determining causal role at all, or they are causes of the neural bases of their relevant 
horizontal mental effects. 

The interlevel relation of contextual emergence yields a quite different perspective on mental 
causation. It dissolves the alleged conflict between horizontal and vertical determination of mental 
events as ill-conceived. The key point is a construction of properly defined mental states from the 
dynamics of an underlying neural system. This can be done via statistical neural states based on a 
proper partition, such that these statistical neural states are coextensive (but not necessarily 
identical) with individual mental states.

This construction implies that the mental dynamics and the neural dynamics, related to each other 
by a so-called intertwiner, are topologically equivalent. Given properly defined mental states, the 
neural dynamics gives rise to a mental dynamics that is independent of those neurodynamical details 
that are irrelevant for a proper construction of mental states.

As a consequence, (i) mental states can indeed be causally and horizontally related to other mental states, 
and (ii) they are neither causally related to their vertical neural determiners nor to the neural determiners 
of their horizontal effects. This makes a strong case against a conflict between a horizontal and a vertical 
determination of mental events and resolves the problem of mental causation in a deflationary manner. 
Vertical and horizontal determination do not compete, but complement one another in a cooperative fashion. 
Both together deflate Kim's dilemma and reflate the causal efficacy of mental states. Our conclusions 
match with and refine the notion of proportionate causation introduced by Yablo.

In this picture, mental causation is a horizontal relation between previous and subsequent mental states, 
although its efficacy is actually derived from a vertical relation: the downward confinement of 
(lower-level) neural states originating from (higher-level) mental constraints. This vertical 
relation is characterized by an intertwiner, a mathematical mapping, which must be distinguished 
from a causal before-after relation. For this reason, the terms downward causation or top-down causation 
are infelicitous choices for addressing a downward confinement by contextual constraints.

Within the tradition of dual-aspect thinking, one can distinguish two different, in a sense opposing 
base conceptions. In one of them, psychophysically neutral elementary entities are composed to sets 
of such entities, and depending on the composition these sets acquire mental or physical properties. 
The other base conception refers to a psychophysically neutral domain which does not consist of 
elementary entities waiting to be composed, but is conceived as one overarching whole that is to 
be decomposed. In contrast to the atomistic picture of compositional dual-aspect monism, the holistic 
picture of the decompositional variant is strongly reminiscent of the fundamental insight of 
entanglement in quantum physics.

The contextual emergence of both the mental and the material from a psychophysically neutral 
whole requires a fresh look at the conceptual framework, both technically and in terms of the 
underlying metaphysics. At the technical level, we do now refer to the contextual emergence of 
multiplicity from unity, fine grains from coarse grains, rather than the other way around. The basic 
idea here is that a "primordial" decomposition of an undivided whole generates (under a particular 
context) different domains that give rise to differentiations, e.g. the mind-matter distinction.

In the decompositional variety of dual-aspect monism, refinement by symmetry breakdown is conceptually 
prior to its opposite of generalization, where the restoration of symmetries generates equivalence 
classes of increasing size. The basic undivided, psychophysically neutral reality is the trivial 
partition where nothing is distinguished. There is full symmetry and, hence, the corresponding 
reality is "ineffable", or "discursively inaccessible". Successive decompositions give rise to 
more and more refined partitions, where symmetries are broken and equivalence classes beome 
smaller and smaller. Phenomenal families of mental states illustrate this for the mental domain.

At the metaphysical level, the mental and the physical remain epistemic, but the undivided whole is added as an ontic dimension. This reminds one of Plato's ideas or Kant's things-in-themselves, which are empirically inaccessible in principle and, in this sense, scientificallly mute. Indeed, an undivided whole cannot be further characterized without introducing distinctions that break up the wholeness. Yet, it provides one asset in the metaphyscis of the mind-matter problem that no other philosophical position provides: the emergence of mind-matter correlations as a direct and immediate consequence.
