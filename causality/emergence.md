# Contextual emergence

## What is contextual emergence?

Contextual emergence is a specific kind of relationship between different
domains of scientific descriptions of particular phenomena. Although these domains 
are not ordered strictly hierarchically, one often speaks of lower and higher levels 
of description in which emergence occurs. From the lower levels (L), more fundamental in a certain
sense, phenomena emerge in higher levels (H) in more complex phenomena. Strings of DNA in a genome
may correspond to different transcripts on an transcriptome level for an individual. Chaotic conditions
may emerge from certain differential equations subject to certain constraints. This complexity depends
on the conditions of the context. Hence, contextual emergence.

Contextual emergence involves  well-defined relationships between different levels of complexity.
We can use a two-step procedure to create a systematic, formal way that an individual
description (Li) creates a statistical description (Ls) among the lower level. This process
can lead us to decribe individuals at a higher level (Hi). We iterate this process (Li -> Ls -> Hi) through
sets of descriptions connected with one another to reveal what emerges at higher levels.

During this method, we identify equivalence classes of individual states that are indistinguishable
with respect to a certain property of the entire system. We can realize different statistical
states in Ls by individual states in Li. Each state has limited knowledge, but, together,
we can create probability distributions represent the statistical states Ls. This could be how
spike signals from neural circuits encode for higher-level functions in the brain.

Then, we can assign individual states at the higher level H to coextensional statistical states at level L.
We use a top-down constraint. This needs information about the higher description to choose a
context setting the framework for the set of observable properties at level H created from L.
We can implement stability criteria at level L such that the appropriate context emerges at level H.
The stability refers to the ability for the features of the system to remain valid even under
small changes. This includes equilibrium states of gas systems and homeostatic relationships
between units of biological mechanisms such as glycolysis. We may also define stability as systems
that have boundaries maintained under the dynamics specified for it We may choose to confine ourselves
to certain electrochemical properties that emerge from membrane dynamics in synaptic networks. This allows
the emergent properties to remain well-defined from the contextual topology of L. It also
tells us which properties of L are relevant to the contextual emergence of H.

This interplay between upward and downard strategies lets the system remain self-consistent.
moving from a higher context to a lower one requires the stability conditions to lead to lower-level
partitions of the system while moving to a higher context means the statistics of lower-level states
extend to higher-level individual states we can observe.

## Point mechanics to statistical mechanics to thermodynamics

We can even demonstrate the relationship between different fields of science through contextual
emergence. Moving from classical point mechanics, involving forces due to gravitational effects and
electromagnetism, to statistical mechanics to thermodynamics illustrates this phenomena. From point mechanics
to statistical mechanics particles or other individual units (Li) form ensemble distributions which can be
studied using statistics. We can define many-particle systems with statistical ensemble descriptions (Ls)
like momenta or energy of distributions, such as the Maxwell-Boltzmann distribution for N particles. From there,
we can find mean kinetic energy, Gibbs free energy, entropy, and other statistical quantities.

We can observe expectation values of momenta distrubitioins of particle ensembles to calculate temperature
of the system as a higher-level function (Hi) on the assumption the system is in equilibrium. The zeroth law
of thermodynamics does not come from statistical mechnics, but from thermodynamics. Other features such as
irreversibility and adiabatic nature emerge as well. We can characterize this thermal equilibrium (Hi)
using Kubo-Martin-Schwinger (KMS) states, defined by the condition that characterizes the structural
stability of a KMS state against local perturbations or changes. This leads to stationarity, ergodicity,
and mixing using the zeroth law of thermodynamics to define the system as stable. We can
also use the second law of thermodynamics to express the stability in maximization of entropy
for thermal equilibrium states.

The first step of the contextual emergence process (Li -> Ls) describes statistical states from the individual
states, and the second gives indiidual thermal states from statistical mechanical states. Other examples may
include emergence of geometric optics from electrodynaimcs, electrical engineering features from electrodynamics,
chirality from quantum mechanics, and diffusion or friction of a quantum particle in a thermal medium.

If descriptions at L and H are well established, as it is the case in the preceding example, 
formally precise interlevel relations can be set up fairly straightforwardly. The situation 
becomes more challenging, though, when no such established descriptions are available, e.g. 
in cognitive neuroscience or consciousness studies, where relations between neural and mental 
descriptions are considered. Even there, contextual emergence has been proven viable for the 
construction of emergent mental states (e.g., the identification of neural correlates of 
conscious states). That brain activity provides necessary but not sufficient conditions for 
mental states, which is a key feature of contextual emergence, becomes increasingly clear 
even among practicing neuroscientists.

A basic element of theoretical and computational neuroscience are the Hodgkin-Huxley equations 
for the generation and propagation of action potentials. The Hodgkin-Huxley equations form a 
system of four ordinary nonlinear differential equations: one electric conductance equation 
for transmembrane currents, and three master equations describing the opening kinetics of 
sodium and potassium ion channels. At a higher-level description of ion channel functioning, 
these equations characterize a deterministic dynamical system. However, at a lower-level 
description, the presence of master equations within the Hodgkin-Huxley system indicates a 
stochastic approach in terms of transition probabilities of Markov processes.

A closer inspection of the Hodgkin-Huxley equations reveals that the dynamics of neuronal action 
potentials is actually contextually emergent over (at least) three levels of description. 
At the first and lowest level, ion channels must be treated as macro-molecular quantum objects 
that are governed by a many-particle Schrödinger equation. This Schrödinger equation describes 
a highly entangled state of electrons and atomic nuclei as a whole, which does not allow 
an interpretation in terms of molecular structures such as an ion channel with a pore that is 
either closed or open. The molecular structure of an ion channel is contextually emergent 
through the Born-Oppenheimer approximation separating electronic and nucleonic wave functions. 
After that separation, the electronic quantum dynamics becomes constrained to a (relatively) 
rigid nucleonic frame that now possesses a classical spatial structure.

At a second level, the fluctuations of the spatial structure of an ion channel must be treated 
as a stochastic process. Under the respective stability conditions for such processes (stationarity, 
ergodicity, mixing a continuous master equation for the molecular configurations can be derived.  
Finally, at the third level, a contextual coarse-graining of configuration space into four closed 
and one open state (here for the potassium channel), yields the master equations of the Hodgkin-Huxley 
system as a contextually emergent description.

Contextual emergence addresses both the construction of a partition at a lower-level description and 
the application of a higher-level context to do this in a way adapted to a specific higher-level 
description. Two alternative strategies have been proposed to contruct Hi-states ("neural macrostates") 
from Li-states ("neural microstates") previously: one by Amari and collaborators and another one by 
Crutchfield and collaborators.

For the contextual emergence of mental states from neural states, the first desideratum is the 
specification of proper levels L and H . With respect to L , one needs to specify whether states 
of neurons, of neural assemblies or of the brain as a whole are to be considered; and with respect 
to H a class of mental states reflecting the situation under study needs to be defined. In a purely 
theoretical approach, this can be tedious, but in empirical investigations the experimental setup 
can often be used for this purpose. For instance, experimental protocols include a task for subjects 
that defines possible mental states, and they include procedures to record brain states.

The first step is to find a proper assignment of Li and Ls at the neural level. A good candidate 
for Li are the properties of individual neurons. Then the first task is to construct Ls in such 
a way that statistical states are based on equivalence classes of those individual states whose 
differences are irrelevant with respect to a given mental state at level H. This reflects that 
a neural correlate of a conscious mental state can be multiply realized by "minimally sufficient 
neural subsystems correlated with states of consciousness" from David Chalmers "What is a neural 
correlate of consciousness?".

In order to identify such a subsystem, we need to select a context at the level of mental states. 
As one among many possibilities, one may use the concept of "phenomenal families" for this purpose. 
A phenomenal family is a set of mutually exclusive phenomenal (mental) states that jointly partition 
the space of mental states. Starting with something like creature consciousness, that is being conscious 
versus being not conscious, one can define increasingly refined levels of phenomenal states of background 
consciousness (awake, dreaming, sleep, anesthesia, ...), wake consciousness (perceptual, cognitive, 
affective, ...), perceptual consciousness (visual, auditory, tactile, ...), visual consciousness 
(color, form, location, ...), and so on.

Selecting one of these levels provides a context which can then be implemented as a stability criterion 
at Ls. In cases like the neural system, where complicated dynamics far from thermal equilibrium are 
involved, a powerful method to do so uses the neurodynamics itself to find proper statistical states. 
The essential point is to identify a partition of the neural state space whose cells are robust under 
the dynamics. This guarantees that individual mental states Hi, defined on the basis of statistical 
neural states Ls, remain well-defined as the system develops in time. The reason is that differences 
between individual neural states Li belonging to the same statistical state Ls remain irrelevant as the 
system develops in time.

The construction of statistical neural states is strikingly analogous to what leads Butterfield to the 
notion of meshing dynamics. In his terminology, L-dynamics and H-dynamics mesh if coarse graining and 
time evolution commute. From the perspective of contextual emergence, meshing is guaranteed by the 
stability criterion induced by the higher-level context. In this picture, meshing translates into 
the topological equivalence of the two dynamics.

For multiple fixed points, their basins of attraction represent proper cells, while chaotic attractors 
need to be coarse-grained by so-called generating partitions. From experimental data, both can be numerically 
determined by partitions leading to Markov chains. These partitions yield a rigorous theoretical constraint 
for the proper definition of stable mental states. The formal tools for the mathematical procedure derive 
from the fields of ergodic theory and symbolic dynamics.

A pertinent example for the application of contextual emergence to experimental data is the relation 
between mental states and EEG dynamics. In a recent study, Allefeld tested the method using data 
from the EEG of subjects with sporadic epileptic seizures. This means that the neural level is 
characterized by brain states recorded via EEG, while the context of normal and epileptic mental 
states essentially requires a bipartition of that neural state space.

The data analytic procedure rests on ideas by Gaveau and Schulman, Froyland, and Deuflhard and Weber. 
It starts with a (for instance) 20-channel EEG recording, giving rise to a state space of dimension 20, 
which can be reduced to a lower number by restricting to principal components (PC). On the resulting 
low-dimensional state space, a homogeneous grid of cells is imposed in order to set up a Markov 
transition matrix T reflecting the EEG dynamics on a fine-grained auxiliary partition. 

The eigenvalues of T express relaxation time scales for the dynamics which can be ordered by size. 
Gaps between successive relaxation times indicate groupings referring to mental states defined by 
partitions of neural states of increasing refinement. The first group is often sufficient for the 
distinction of "target" mental states.

The eigenvectors corresponding to the eigenvalues of T span an eigenvector space, in which the 
measured PC-compactified states form a simplex. For instance, three leading eigenvalues allow a 
representation of neural states in a two-dimensional eigenvector space which yields a 2-simpex 
with 3 vertices (a triangle). Classifying the measured neural states according to their distance 
from the vertices of the simplex then leads to three clusters of neural data. They can be coded 
and identified in the PC-state space, where the clusters appear as non-intersecting convex sets 
distinguishing one normal state and one seizure state (composed of two substates).

Finally, the result of the partitioning can be inspected in the originally recorded time series to 
check whether mental states are reliably assigned to the correct episodes in the EEG dynamics. 
The study by Allefeld shows perfect agreement between the distinction of normal and epileptic 
states and the bipartition resulting from the spectral analysis of the neural transition matrix.

Another EEG-segmentation algorithm that uses the recurrence structure of multivariate time series 
has been suggested by beim Graben and Hutt. Their recurrence structure analysis (RSA) partitions 
the state space into clusters of recurrent, and therefore, overlapping balls obtained from the 
recurrence plot of the dynamical system. Different choices of the radius r of the balls leads to 
potentially different segmentations of the time series from the corresponding partitions. An 
optimal choice of r, however, will ideally reflect the dwell times within metastable states and 
the transitions between metastable states. This can be described by a Markov chain with one 
distinguished transient state and other states representing the metastable states in the dynamics.

The deviation of a given contextual segmentation from the optimal segmentation can be assessed 
using a utility function whose maximization leads to a contextually emergent brain microstate 
segmentation of the EEG. Applying this technique to EEG data from anesthetized ferrets and to 
event-related brain potentials from human language-processing experiments revealed good correlation 
with mental states.

According to Dennett, the intentional stance can be applied to the prediction of any system's 
behavior that is too complex to be treated as either a physical or a designed system. Intentional 
systems in this sense are systems whose behavior is predictable upon ascribing beliefs and desires to 
their internal states. Examples for intentional systems range from thermostats and chess computers 
over "magnetic snakes" to "true believers", e.g. human beings.

To make meaningful predictions of a system, several necessary and sufficient conditions on the 
system's dynamics must be fulfilled (beim Graben 2014). First of all, the system's dynamics 
must be non-trivial, thus excluding most kinds of linear systems with periodic oscillations 
or damped relaxations. The class of putative intentional systems can be embedded into an 
"intentional hierarchy" ranging from the general case of nonlinear nonequilibrium dissipative 
systems to more specific intentional systems and "true believers" as a subclass.

Being a physical system is necessary for being a nonlinear dissipative nonequilibrium system; 
being a nonlinear dissipative nonequilibrium system is necessary for being an intentional system; 
and being an intentional system is necessary for being a true believer. Moreover, sufficient 
conditions within the intentional hierarchy implement contextual stability conditions.

The most general case corresponds to the transition from equilibrium thermodynamics to fluid dynamics: 
The phenomenal laws of fluid dynamics (the Navier-Stokes equations) emerge from statistical mechanics 
under the assumption of "local equilibrium". At the next level, several sufficient boundary conditions 
must be selected to give rise to processes of self-organization, nicely illustrated by means of "magnetic 
snakes". Then, a rationality constraint is imposed for optimal dissipation of pumped energy. 
Finally, "true believers" are contextually emergent as intentional systems that are stable under 
mutual adoption of the intentional stance. 

Another application of contextual emergence refers to the symbol grounding problem posed by Harnad. The 
key issue of symbol grounding is the problem of assigning meaning to symbols on purely syntactic grounds, 
as proposed by cognitivists such as Fodor and Pylyshin (1988). This entails the question of how conscious 
mental states can be characterized by their neural correlates, see Atmanspacher and beim Graben. Viewed 
from a more general perspective, symbol grounding has to do with the relation between analog and digital 
systems, the way in which syntactic digital symbols are related to the analog behavior of a system they 
describe symbolically.

An instructive example for this distinction is given by dynamical automata. These are piecewise linear 
(globally nonlinear) time-discrete maps over a two-dimensional state space which assume their interpretation 
as symbolic computers through a rectangular partition of the unit square. Interestingly, a single point 
trajectory, i.e. the evolution of microstates (at a lower level description) is not fully interpretable as 
symbolic computation. Therefore, one has to consider (higher-level) macrostates, based on ensembles of 
state space points (or probability distributions of points) that evolve under the dynamics.

Beim Graben and Potthast showed that only uniform probability distributions with rectangular support 
exhibit a stable dynamics that is interpretable as computation. Thus, the huge space of possible 
probability distributions must be contextually restricted to the subclass of uniform probability 
distributions in order to obtain meaningfully grounded symbolic processes. In this sense, symbol 
grounding is contextually emergent.

It is a long-standing philosophical puzzle how the mind can be causally relevant in a physical world: 
the problem of mental causation the question of how mental phenomena can be causes is of high significance 
for an adequate comprehension of scientific disciplines such as psychology and cognitive neuroscience. 
Moreover, mental causation is crucial for our everyday understanding of what it means to be an agent 
in a natural and social environment. Without the causal efficacy of mental states the notion of agency 
would be nonsensical.

One of the reasons why the causal efficacy of the mental has appeared questionable is that a 
horizontal (intralevel, diachronic) determination of a mental state by prior mental states 
seems to be inconsistent with a vertical (interlevel, synchronic) determination of that mental 
state by neural states. In a series of influential papers and books, Kim has presented his much 
discussed supervenience argument (also known as exclusion argument), which ultimately amounts to 
the dilemma that mental states either are causally inefficacious or they hold the threat of 
overdetermining neural states. In other words: either mental events play no horizontally 
determining causal role at all, or they are causes of the neural bases of their relevant 
horizontal mental effects. 

The interlevel relation of contextual emergence yields a quite different perspective on mental 
causation. It dissolves the alleged conflict between horizontal and vertical determination of mental 
events as ill-conceived. The key point is a construction of properly defined mental states from the 
dynamics of an underlying neural system. This can be done via statistical neural states based on a 
proper partition, such that these statistical neural states are coextensive (but not necessarily 
identical) with individual mental states.

This construction implies that the mental dynamics and the neural dynamics, related to each other 
by a so-called intertwiner, are topologically equivalent. Given properly defined mental states, the 
neural dynamics gives rise to a mental dynamics that is independent of those neurodynamical details 
that are irrelevant for a proper construction of mental states.

As a consequence, (i) mental states can indeed be causally and horizontally related to other mental states, 
and (ii) they are neither causally related to their vertical neural determiners nor to the neural determiners 
of their horizontal effects. This makes a strong case against a conflict between a horizontal and a vertical 
determination of mental events and resolves the problem of mental causation in a deflationary manner. 
Vertical and horizontal determination do not compete, but complement one another in a cooperative fashion. 
Both together deflate Kim's dilemma and reflate the causal efficacy of mental states. Our conclusions 
match with and refine the notion of proportionate causation introduced by Yablo.

In this picture, mental causation is a horizontal relation between previous and subsequent mental states, 
although its efficacy is actually derived from a vertical relation: the downward confinement of 
(lower-level) neural states originating from (higher-level) mental constraints. This vertical 
relation is characterized by an intertwiner, a mathematical mapping, which must be distinguished 
from a causal before-after relation. For this reason, the terms downward causation or top-down causation 
are infelicitous choices for addressing a downward confinement by contextual constraints.

Within the tradition of dual-aspect thinking, one can distinguish two different, in a sense opposing 
base conceptions. In one of them, psychophysically neutral elementary entities are composed to sets 
of such entities, and depending on the composition these sets acquire mental or physical properties. 
The other base conception refers to a psychophysically neutral domain which does not consist of 
elementary entities waiting to be composed, but is conceived as one overarching whole that is to 
be decomposed. In contrast to the atomistic picture of compositional dual-aspect monism, the holistic 
picture of the decompositional variant is strongly reminiscent of the fundamental insight of 
entanglement in quantum physics.

The contextual emergence of both the mental and the material from a psychophysically neutral 
whole requires a fresh look at the conceptual framework, both technically and in terms of the 
underlying metaphysics. At the technical level, we do now refer to the contextual emergence of 
multiplicity from unity, fine grains from coarse grains, rather than the other way around. The basic 
idea here is that a "primordial" decomposition of an undivided whole generates (under a particular 
context) different domains that give rise to differentiations, e.g. the mind-matter distinction.

In the decompositional variety of dual-aspect monism, refinement by symmetry breakdown is conceptually 
prior to its opposite of generalization, where the restoration of symmetries generates equivalence 
classes of increasing size. The basic undivided, psychophysically neutral reality is the trivial 
partition where nothing is distinguished. There is full symmetry and, hence, the corresponding 
reality is "ineffable", or "discursively inaccessible". Successive decompositions give rise to 
more and more refined partitions, where symmetries are broken and equivalence classes beome 
smaller and smaller. Phenomenal families of mental states illustrate this for the mental domain.

At the metaphysical level, the mental and the physical remain epistemic, but the undivided whole 
is added as an ontic dimension. This reminds one of Plato's ideas or Kant's things-in-themselves, 
which are empirically inaccessible in principle and, in this sense, scientificallly mute. Indeed, 
an undivided whole cannot be further characterized without introducing distinctions that break up 
the wholeness. Yet, it provides one asset in the metaphyscis of the mind-matter problem that no 
other philosophical position provides: the emergence of mind-matter correlations as a direct and 
immediate consequence.

Determinism is often understood as a feature of ontic descriptions of states and observables 
whereas stochasticity refers to epistemic descriptions . Mathematical models 
of classical point mechanics are most common examples of deterministic descriptions, and three 
properties of these descriptions are particularly important: (1) differential 
dynamics, (2) unique evolution, and (3) value determinateness. (1) means essentially that the 
system's evolution obeys a differential equation (or some similar algorithm) in a space of 
ontic states. (2) says that for given initial and boundary conditions there is a unique 
trajectory. (3) assumes that any state be described with arbitrarily small (non-zero) error.

These three points are not independent from each other but define a hierarchy for the contextual 
emergence of deterministic descriptions assuming (1) as a necessary condition for determinism, 
(2) can be proven under the sufficient condition that the trajectories created by a vector field 
obeying (1) pass through points whose distance is stable under small perturbations. Assuming (2) 
for almost every initial condition as a necessary condition of determinism defines a phase flow 
with weak causality. In order to prove (3) one needs strong causality as a sufficient condition.

For a weakly causal system violating (3), trajectories may exponentially diverge, as in chaotic systems. 
In this situation, dilation techniques can lead to contextually emergent
stochasticity in two steps. In the first step, a coarse-graining yields a Markov process. If this 
process is mixing such that it approaches an equilibrium distribution, the deterministic 
dynamics is a Kolmogorov-flow, thereby implementing microscopic chaos as a stability condition.
 
Interestingly, the converse is also possible. For a continuous stochastic process which 
fulfills the Markov criterion, the master equation approach leads to a deterministic "mean-field equation". 
Bishop and beim Graben showed that this situation is analogous to the paradigmatic example of the 
contextual emergence of thermal equilibrium states where thermal KMS macrostates are almost pure, and 
hence almost dispersion-free.

Reproducibility is one of the pillars of scientific methodology, yet it becomes particularly 
difficult in interdisciplinary research where the results to be reproduced typically refer to 
more than one single level of description of the system considered. In such cases it is mandatory 
to distinguish the relevant attributes or observables of the system, depending on its description. 
Usually, different descriptive levels go along with different degrees of granularity. While lower-level 
descriptions address systems in terms of micro-properties (position, momentum, etc.), other, more global, 
macro-properties are more suitably taken into account for higher-level descriptions.

This observation led van Fraassen to the notion of explanatory relativity, where explanations
are not only relationships between theories and facts; they are three-place relations between theories, 
facts, and contexts. The relevance of an explanation is determined by contexts that have to be selected, 
and are not themselves part of a scientific description.

Explanatory relativity backed up by relevance criteria can vitally serve the discussion of reproducibility 
across scientific disciplines. Features that are relevant for a proper explanation of some 
observation should have a high potential to be also relevant for the robust reproduction 
of that observation. But which properties of systems and their descriptions may be promising 
candidates for the application of such relevance criteria? One option to highlight relevance 
criteria is to consider the "granularity" (coarseness) of a description, which usually changes across disciplines.

The transformation between descriptive levels and their associated granularities is possible 
by the interlevel relation of contextual emergence. It yields a formally sound and empirically 
applicable procedure to construct level-specific criteria for relevant observables across disciplines. 
Relevance criteria merged with contextual emergence challenge the old idea of one fundamental 
ontology from which everything else derives. At the same time, the scheme of contextual emergence 
is specific enough to resist the backlash into a relativist patchwork of unconnected model fragments.

Contextual emergence has been originally conceived as a relation between levels of descriptions, 
not levels of nature: It addresses questions of epistemology rather than ontology. In agreement with Esfeld, 
who advocated that ontology needs to regain more significance in science, it would be desirable to 
know how ontological considerations might be added to the picture that contextual emergence provides.

A network of descriptive levels of varying degrees of granularity raises the question of whether 
descriptions with finer grains are more fundamental than those with coarser grains. The 
majority of scientists and philosophers of science in the past tended to answer this question 
affirmatively. As a consequence, there would be one fundamental ontology, preferentially that of 
elementary particle physics, to which the terms at all other descriptive levels can be reduced.

But this reductive credo also produced critical assessments and alternative proposals. A philosophical 
precursor of trends against a fundamental ontology is Quine's ontological relativity. Quine 
argued that if there is one ontology that fulfills a given descriptive theory, then there is more 
than one. It makes no sense to say what the objects of a theory are, beyond saying how to interpret or 
reinterpret that theory in another theory. Putnam later developed a related kind of 
ontological relativity, first called internal realism, later sometimes modified to pragmatic realism.

On the basis of these philosophical approaches, Atmanspacher and Kronz suggested how to apply Quine's 
ideas to concrete scientific descriptions, their relationships with one another, and with their referents. 
One and the same descriptive framework can be construed as either ontic or epistemic, depending on 
which other framework it is related to: bricks and tables will be regarded as ontic by an architect, 
but they will be considered highly epistemic from the perspective of a solid-state physicist.

Coupled with the implementation of relevance criteria due to contextual emergence, the relativity of 
ontology must not be confused with dropping ontology altogether. The "tyranny of relativism" (as 
some have called it) can be avoided by identifying relevance criteria to distinguish proper 
context-specific descriptions from less proper ones. The resulting picture is more subtle and 
more flexible than an overly bold reductive fundamentalism, and yet it is more restrictive and 
specific than a patchwork of arbitrarily connected model fragments.
