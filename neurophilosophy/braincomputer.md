# The brain-computer interface

An output of a computer depends on its program, input, and functional stages that lead to the output.

## Intentionality 

If we treat propositional attitudes with intentionality as a physical properties, we can build a computer
with states that have genuine intentionality. But no computer model that stimulates human propositional
attitudes will have genuine intentional states. Intentionality of propositional attitudes isn't a physical
property. 

We may consider the network theory of meaning (or holistic theory or conceptual-role theory) such that the meaning
of an expression plays a role in its internal representatinoal economy. This way it relates to sensory input and
behavioral output. Meaning is relational as an expression's meaning is a function of its inferential and computational
role in a person's internal system. A robot that behaves like a human is still subject to the quesitno of whether
those thoughts it generates have the same meaning that represent our own meaning. Assigning meaning to the internal
states of a robot would be applying a double standard arbitrarily with no useful purpose. The robot's internal 
machinery doesn't change that it believes, wants, and understands things. The robot's intentional states depend
on how complex its internal informational network of states it has.

We need altogehter a better theory of representation in organisms much the same way we have theoretical definitions
and ideas of what molecules, proteins, and neutrons are.  
